{"./":{"url":"./","title":"介绍","keywords":"","body":"Attack on Tornado 🌪️ 介绍 🐙 致力构建一个高质量的后端技术图谱 这是一个有深度的 Tornado 系列博客 , 在线阅读 体验更丝滑哟 本目录下源码环境 : - asyncio version: 3.4.3 - tornado version: 6.1 目录 🚀 IO模型 BIO实现 NIO实现 IO Multiplexing实现 SIGIO实现 AIO实现 生成器 协程 AIO协程实现 "},"SUMMARY.html":{"url":"SUMMARY.html","title":"目录","keywords":"","body":"Attack on Tornado 🌪️ 介绍 目录 IO模型 BIO实现 NIO实现 IO-Multiplexing实现 SIGIO实现 AIO实现 生成器 协程 AIO协程实现 asyncio IOLoop "},"01-IO模型.html":{"url":"01-IO模型.html","title":"IO模型","keywords":"","body":"Attack on Tornado - IO模型 🌪 前言 在开始介绍IO模型之前 , 我们需要弄清楚两组概念 阻塞 , 非阻塞 , 同步 , 异步 通常我们容易把这两组概念混淆 , 比如: 同步和阻塞在我们程序执行时好像是一样的? 异步和非阻塞也好像没什么区别 实际上这两组概念 , 可能从某些现象来说是有点相似 , 但实际上它们的关注点其实是不一样的 同步与异步 同步和异步关注的是消息通信机制 , 也就是同步通信还是异步通信 所谓同步 , 就是在发出一个功能调用时 , 在没有得到结果之前，该调用就不会返回 . 按照这个定义，其实绝大多数函数都是同步调用 . 但是一般而言 , 我们在说同步、异步的时候 , 特指那些需要其他部件协作或者需要一定时间完成的任务 异步的概念和同步相对 , 当一个异步功能调用发出后 , 调用者不能立刻得到结果 . 当该异步功能完成后 , 通过状态、通知或回调来通知调用者 , 如果异步功能用状态来通知 , 那么调用者就需要每隔一定时间检查一次 , 效率就很低(有些初学多线程编程的人 , 总喜欢用一个循环去检查某个变量的值 , 这其实是一 种很严重的错误) . 如果是使用通知的方式 , 效率则很高 , 因为异步功能几乎不需要做额外的操作 . 至于回调函数 , 其实和通知没太多区别 阻塞非阻塞 阻塞和非阻塞关注的是程序在等待调用结果时的状态 阻塞调用是指调用结果返回之前，当前线程会被挂起（如遇到io操作）。函数只有在得到结果之后才会将阻塞的线程激活。有人也许会把阻塞调用和同步调用等同起来，实际上他是不同的。对于同步调用来说，很多时候当前线程还是激活的，只是从逻辑上当前函数没有返回而已 非阻塞和阻塞的概念相对应，指在不能立刻得到结果之前也会立刻返回，同时该函数不会阻塞当前线程 弄清楚这两组概念我们才能更好的去理解接下来的IO模型 在I/O流程中 , 一般可以分为两个阶段 : 数据准备阶段 , 这个阶段需要等待接收网络数据 , 当数据包到达时 , 内核会将数据包拷贝到内核缓冲区 数据拷贝阶段 , 这个阶段数据包会从内核缓冲区复制到我们的应用程序缓冲区 I/O模型的差异就来自于在这两个阶段上 , 不同的I/O模型有会不同的表现 阻塞IO 在Linux中 , 默认情况下所有的 socket 都是阻塞的 , 流程如上图 当用户进程调用了 recvfrom 这个系统调用时 , kernel 就进入了第一个阶段 , 这个阶段整个进程会被阻塞 , kernel 等到数据准备好了之后 , 就会将数据从 kernel 拷贝到用户内存 , 然后 kernel 返回结果 , 用户进程才解除阻塞状态 , 继续执行 所以 , 阻塞IO的特点就是在IO执行的两个阶段用户进程都被阻塞了 非阻塞IO 很明显 , 阻塞IO对CPU是一种极大的浪费 , 大部分时间用户进程都是阻塞的 在非阻塞IO中 , 我们可以将 socket 设置成非阻塞 , 而用户进程在调用 recvfrom 时 , 如果数据没有准备好 , 那么直接返回一个 error , 这样用户进程就知道数据还没有准备好 , 于是它可以再次发送 recvfrom 系统调用 , 直到数据准备完成 , 这个时候用户进程阻塞 , kernel 开始拷贝数据到用户程序缓冲区 , 拷贝完成之后解除阻塞 所以 , 非阻塞IO , 用户在数据准备阶段会不断的轮询 kernel , 这个过程是不会阻塞的 , 但是在数据拷贝阶段 recvfrom 依然是阻塞的 虽然非阻塞IO模型在第一阶段不会阻塞了 , 但是大量的 recvfrom 系统调用会大幅度提高 CPU 的暂用率 , 且可能会有很多无效的 recvfrom , 所以非阻塞IO模型一般不被推荐 IO多路复用 在IO多路复用中 , 我们在调用 recvfrom 之前 , 先调用 select , select 会不断轮询所以的 socket (socket 会被设置成 nonblocking ) , 直到 select 中某个 socket 有数据才返回 , 否则将会一直阻塞 用户进程拿到可读的 socket 时 , 此时再去调用 recvfrom 将数据复制到应用程序缓冲区 所以 , IO多路复用的特点就是提高了 recvfrom 的效率 , 只有当数据准备好时才会去调用 , 不过IO多路复用多出了一个 select 系统调用 IO多路复用的具体实现有 :select , poll , epoll , kqueue 等等 信号驱动IO 我们知道在IO多路复用中 , select 还是会阻塞用户进程 , 而在信号驱动IO中 , 首先开启套接字的信号驱动功能 , 然后使用 sigaction 系统调用绑定信号处理程序 , 这个系统调用是立即返回的 当数据准备好时 , 内核会向用户进程发送 SIGIO 信号 , 应用进程在接收到信号之后再调用 recvfrom 将数据从内核复制到用户程序缓冲区中 所以 , 信号驱动IO的特点就是在IO多路复用的基础上 , 把 select 这一个阻塞调用也去除了 , 第一阶段完全非阻塞 , 当然第二阶段还是阻塞的 异步IO 在上面我们分析了阻塞IO , 非阻塞IO , IO多路复用 , 信号驱动IO , 实际上都没有解决第二阶段的阻塞问题 也就是说阻塞IO , 非阻塞IO , IO多路复用 , 信号驱动IO 都属于同步IO 那就明了了 , 异步IO就是实现两阶段全部非阻塞 当请求进程发起读操作时 , 内核会立刻返回 , 不会阻塞请求进程 , 内核在数据准备完成后 , 会将数据拷贝到用户程序缓冲区 , 当所有这些工作全部完成 , 内核会通知请求进程 , IO操作已完成 所以 , 异步IO的特点就是信号驱动IO是通知用户进程现在可以开始拷贝了 , 而异步IO则是通知用户进程已经拷贝完成了 , 实现真正的两阶段非阻塞 异步IO好是好 , 但是当前Linux对异步IO的支持并不成熟 , 更多的还是基于IO多路复用去达到我们的用户层异步 IO模型比较 最后 , 这个图就非常的简单了 后续我们来通过代码去实现这些IO模型 "},"02-BIO实现.html":{"url":"02-BIO实现.html","title":"BIO实现","keywords":"","body":"Attack on Tornado - BIO实现 🌪 前言 这一章中我们来用 Python 实现 BIO (Blocking IO) 也就是阻塞IO BIO 实际上 , 默认的 socket 就是阻塞的 , 所以我们可以直接这样来实现 bio_server.py import socket def server(host, port): sock = socket.socket() sock.bind((host, port)) print('启动服务端...') # listen(5) 表示允许等待的最大数量 sock.listen(5) conn, addr = sock.accept() # 真实场景下当然不会只接收1024个字节的数据就关闭掉, 而是会根据包的大小来进行处理 data = conn.recv(1024).decode('utf-8') print(data) conn.close() sock.close() print('关闭服务端...') if __name__ == '__main__': server('localhost', 8888) http_client.py.py import socket import json import datetime def client(host, port): sock = socket.socket() sock.connect((host, port)) data = { 'send_user': 'Lyon', 'send_time': datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'), 'send_msg': 'BIO test...' } sock.send(json.dumps(data).encode('utf-8')) sock.close() print('客户端发送数据成功...') if __name__ == '__main__': client('localhost', 8888) 接下里我们让服务端可以一直不停的跑 循环BIO 我们可以直接加一个死循环 , 让服务端可以一直不断的处理 , 至于客户端我们并不需要更改 bio_server.py import socket def server(host, port): sock = socket.socket() sock.bind((host, port)) print('启动服务端...') # listen(5) 表示允许等待的最大数量 sock.listen(5) while True: conn, addr = sock.accept() # 真实场景下当然不会只接收1024个字节的数据就关闭掉, 而是会根据包的大小来进行处理 data = conn.recv(1024).decode('utf-8') print(data) conn.close() sock.close() print('关闭服务端...') if __name__ == '__main__': server('localhost', 8888) 这样就可以不断的进行处理了 , 但是如果我们想要同时处理多个客户端连接这是不支持的 所以我们可以再进阶一下 , 每一个连接都用一个线程去进行处理 , 来实现同时处理多个连接 多线程BIO bio_server.py import socket import threading def handle_conn(conn, addr): # 真实场景下当然不会只接收1024个字节的数据就关闭掉, 而是会根据包的大小来进行处理 data = conn.recv(1024).decode('utf-8') print('线程 %s 处理来自 %s-%s 的连接...' % (threading.currentThread().getName(), addr[0], addr[1])) print(data) conn.close() def server(host, port): sock = socket.socket() sock.bind((host, port)) print('启动服务端...') # listen(5) 表示允许等待的最大数量 sock.listen(5) while True: conn, addr = sock.accept() print('客户端 %s-%s 连接成功, 等待发送数据...' % (addr[0], addr[1])) handle = threading.Thread(target=handle_conn, args=(conn, addr)) handle.start() sock.close() print('关闭服务端...') if __name__ == '__main__': server('localhost', 8888) "},"03-NIO实现.html":{"url":"03-NIO实现.html","title":"NIO实现","keywords":"","body":"Attack on Tornado - NIO实现 🌪 前言 这一章中我们来用 Python 实现 NIO (Non-blocking IO) 也就是非阻塞IO NIO 在IO模型的讲解中 , 我们已经知道 , recvfrom 系统调用之后 , 进程并没有阻塞 , 内核马上返回给进程 , 如果数据还没准备好 , 此时会返回一个 error 而进程在返回之后 , 可以做别的事情 , 然后再发起 recvfrom 系统调用 , 一直重复直到拿到数据为止 , 所以我们需要不断的进行轮询 nio_server.py import socket def server(host, port): sock = socket.socket() # 将socket设置为非阻塞 sock.setblocking(False) sock.bind((host, port)) print('启动服务端...') # listen(5) 表示允许等待的最大数量 sock.listen(5) conn_queue = [] delete_conn = [] while True: try: # 因为socket被设置成了非阻塞, 所以这里不会阻塞 # 且当没有连接进来时, 这里也会一直error conn, addr = sock.accept() conn_queue.append((conn, addr)) except BlockingIOError as e: for c in conn_queue: conn, addr = c try: # 真实场景下当然不会只接收1024个字节的数据就关闭掉, 而是会根据包的大小来进行处理 # recv同样是非阻塞的, 所以也需要捕捉一下BlockingIOError data = conn.recv(1024).decode('utf-8') print(data) delete_conn.append(c) conn.close() except BlockingIOError: pass for c in delete_conn: conn_queue.remove(c) delete_conn = [] sock.close() print('关闭服务端...') if __name__ == '__main__': server('localhost', 8888) http_client.py.py import socket import json import datetime def client(host, port): sock = socket.socket() sock.connect((host, port)) data = { 'send_user': 'Lyon', 'send_time': datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'), 'send_msg': 'BIO test...' } sock.send(json.dumps(data).encode('utf-8')) sock.close() print('客户端发送数据成功...') if __name__ == '__main__': client('localhost', 8888) 当然关于连接队列 , 我们还可以进行优化 , 这里只是为了实现 , 就不做优化了 这样我们就实现了一个 NIO 模型 , 但是在服务端中 , 只是等待请求和准备数据是非阻塞的而已 , 而在处理请求的时候还是阻塞处理的 , 这样的话就导致在处理连接时 , 就无法再接受连接了 , 所以我们可以和 BIO 一样利用多线程来处理连接 多线程NIO nio_server.py import socket import threading def handle_conn(conn, addr): while True: try: data = conn.recv(1024).decode('utf-8') print('线程 %s 处理来自 %s-%s 的连接...' % (threading.currentThread().getName(), addr[0], addr[1])) print(data) conn.close() break except BlockingIOError: pass conn.close() def server(host, port): sock = socket.socket() # 将socket设置为非阻塞 sock.setblocking(False) sock.bind((host, port)) print('启动服务端...') # listen(5) 表示允许等待的最大数量 sock.listen(5) while True: try: # 因为socket被设置成了非阻塞, 所以这里不会阻塞 # 且当没有连接进来时, 这里也会一直error conn, addr = sock.accept() print('客户端 %s-%s 连接成功, 等待发送数据...' % (addr[0], addr[1])) handle = threading.Thread(target=handle_conn, args=(conn, addr)) handle.start() except BlockingIOError as e: pass sock.close() print('关闭服务端...') if __name__ == '__main__': server('localhost', 8888) "},"04-IO-Multiplexing实现.html":{"url":"04-IO-Multiplexing实现.html","title":"IO-Multiplexing实现","keywords":"","body":"Attack on Tornado - IO Multiplexing实现 🌪 前言 这一章中我们来用 Python 实现 IO Multiplexing 也就是IO多路复用 IO Multiplexing 实现IO多路复用需要借助到 selectors selectors 中为我们提供了 select , poll , epoll , kqueue , devpoll iom_server.py import socket import selectors def server(host, port): sock = socket.socket() sock.bind((host, port)) print('启动服务端...') # listen(5) 表示允许等待的最大数量 sock.listen(5) # 获取IO多路复用器, 这里会根据系统选择相应的多路复用器 selector = selectors.DefaultSelector() # 将socket注册进多路复用器 selector.register(sock, selectors.EVENT_READ) while True: # 进行select调用 ready = selector.select() for r in ready: sock = r[0][0] conn, addr = sock.accept() data = conn.recv(1024).decode('utf-8') print(data) conn.close() sock.close() print('关闭服务端...') if __name__ == '__main__': server('localhost', 8888) http_client.py.py import socket import json import datetime def client(host, port): sock = socket.socket() sock.connect((host, port)) data = { 'send_user': 'Lyon', 'send_time': datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'), 'send_msg': 'BIO test...' } sock.send(json.dumps(data).encode('utf-8')) sock.close() print('客户端发送数据成功...') if __name__ == '__main__': client('localhost', 8888) 多线程IO Multiplexing 相信从前面的几篇实现 , 你已经轻车熟路了 iom_server.py import socket import selectors import threading def handle_conn(conn, addr): data = conn.recv(1024).decode('utf-8') print('线程 %s 处理来自 %s-%s 的连接...' % (threading.currentThread().getName(), addr[0], addr[1])) print(data) conn.close() def server(host, port): sock = socket.socket() sock.bind((host, port)) print('启动服务端...') # listen(5) 表示允许等待的最大数量 sock.listen(5) selector = selectors.DefaultSelector() selector.register(sock, selectors.EVENT_READ) while True: ready = selector.select() for r in ready: sock = r[0][0] conn, addr = sock.accept() print('客户端 %s-%s 连接成功, 等待发送数据...' % (addr[0], addr[1])) handle = threading.Thread(target=handle_conn, args=(conn, addr)) handle.start() sock.close() print('关闭服务端...') if __name__ == '__main__': server('localhost', 8888) "},"05-SIGIO实现.html":{"url":"05-SIGIO实现.html","title":"SIGIO实现","keywords":"","body":"Attack on Tornado - SIGIO实现 🌪 前言 这一章中我们来用 Python 实现 SIGIO , 也就是信号驱动IO (Signal driven IO) , 我们需要借助两个标准库 : signal : 信号支持 fcntl : 设置非阻塞文件描述符 实际上信号驱动IO对于 TCP 套接字的作用并不大 , 因为在 TCP 中 SIGIO 信号产生的条件有很多 : 监听套接字上某个连接请求已经完成 某个断连请求已经发起 某个断连请求已经完成 某个连接半关闭 数据到达套接字 数据已经从套接字发送走 套接字上发生异步错误 当然我们还是可以通过 SIGIO 来监听套接字 而在 UDP 中 SIGIO 信号产生的条件仅仅 : 数据到达套接字 套接字上发生异步错误 UDP SIGIO 我们先来实现一个 UDP 的 SIGIO udp_sigio_server.py import os import time import fcntl import signal import socket def server(host, port): sock = socket.socket(type=socket.SOCK_DGRAM) sock.setblocking(False) sock.bind((host, port)) def receive_signal(signum, stack): data, addr = sock.recvfrom(1024) data = data.decode('utf-8') print(data) signal.signal(signal.SIGIO, receive_signal) fcntl.fcntl(sock.fileno(), fcntl.F_SETOWN, os.getpid()) fcntl.fcntl(sock.fileno(), fcntl.F_SETFL, fcntl.fcntl(sock.fileno(), fcntl.F_GETFL, 0) | fcntl.FASYNC) while True: print('Waiting...') time.sleep(3) if __name__ == '__main__': server('localhost', 8888) http_client.py.py import json import socket import datetime def client(host, port): sock = socket.socket(type=socket.SOCK_DGRAM) data = { 'send_user': 'Lyon', 'send_time': datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'), 'send_msg': 'BIO test...' } sock.sendto(json.dumps(data).encode('utf-8'), (host, port)) sock.close() print('客户端发送数据成功...') if __name__ == '__main__': client('localhost', 8888) TCP SIGIO tcp_sigio_server.py import os import time import fcntl import socket import signal def server(host, port): sock = socket.socket() sock.setblocking(False) sock.bind((host, port)) sock.listen() def receive_signal(signum, stack): try: conn, addr = sock.accept() data = conn.recv(1024).decode('utf-8') print(data) conn.close() except BlockingIOError: pass signal.signal(signal.SIGIO, receive_signal) fcntl.fcntl(sock.fileno(), fcntl.F_SETOWN, os.getpid()) fcntl.fcntl(sock.fileno(), fcntl.F_SETFL, fcntl.fcntl(sock.fileno(), fcntl.F_GETFL, 0) | fcntl.FASYNC) while True: print('Waiting...') time.sleep(3) if __name__ == '__main__': server('localhost', 8888) TODO : 单线程下存在问题 , 暂时还没弄清楚 在 Mac 环境下 , 多线程版本暂时没发现问题 thread_tcp_sigio_server.py import os import time import fcntl import socket import signal import threading def handle_conn(conn, addr): while True: try: data = conn.recv(1024).decode('utf-8') print('线程 %s 处理来自 %s-%s 的连接...' % (threading.currentThread().getName(), addr[0], addr[1])) print(data) conn.close() break except BlockingIOError: pass conn.close() def server(host, port): with socket.socket() as sock: sock.setblocking(False) sock.bind((host, port)) sock.listen() def receive_signal(signum, stack): print('SIGIO...') try: conn, addr = sock.accept() handle = threading.Thread(target=handle_conn, args=(conn, addr)) handle.start() except BlockingIOError: pass signal.signal(signal.SIGIO, receive_signal) fcntl.fcntl(sock.fileno(), fcntl.F_SETOWN, os.getpid()) fcntl.fcntl(sock.fileno(), fcntl.F_SETFL, fcntl.fcntl(sock.fileno(), fcntl.F_GETFL, 0) | fcntl.FASYNC) while True: print('Waiting...') time.sleep(3) if __name__ == '__main__': server('localhost', 8888) tcp_sigio_client.py import socket import json import datetime def client(host, port): sock = socket.socket() sock.connect((host, port)) data = { 'send_user': 'Lyon', 'send_time': datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'), 'send_msg': 'BIO test...' } sock.send(json.dumps(data).encode('utf-8')) sock.close() print('客户端发送数据成功...') if __name__ == '__main__': client('localhost', 8888) "},"06-AIO实现.html":{"url":"06-AIO实现.html","title":"AIO实现","keywords":"","body":"Attack on Tornado - AIO实现 🌪 前言 在上一章中 , 我们已经知道信号驱动IO对于我们的 TCP 应用来说 , 支持并不是很好 且不幸的是在 Linux 上的异步IO支持并不成熟 , 虽然相对来说 Windows 上可能要成熟一些 , 但是我们的服务更多的是在 Linux 环境下运行 在第4章的 IO-Multiplexing实现 中 , 我们通过 selectors 实现了基于事件的处理方式 , 实际上 selectors 还支持注册回调函数 , 以此来实现我们应用层的异步IO 我们将每一个IO操作都在回调函数中完成 , 当一个IO事件发生时 , 通过调用回调函数 , 达到异步执行的效果 , 但是注意这个回调并不是由操作系统完成的 , 而是由我们的应用程序来完成的 , 毕竟我们并不是基于操作系统的异步IO来实现的 回调函数 aio_server.py import socket from selectors import DefaultSelector, EVENT_READ def server(host, port): selector = DefaultSelector() sock = socket.socket() sock.bind((host, port)) sock.listen(5) sock.setblocking(False) # 定义请求回调 def accept(sock, mask): conn, addr = sock.accept() # 定义链接回调 def handle_conn(conn, mask): data = conn.recv(1024).decode('utf-8') print(data) conn.close() selector.unregister(conn) selector.register(conn, EVENT_READ, handle_conn) selector.register(sock, EVENT_READ, accept) print('启动服务端...') while True: ready = selector.select() for event, mask in ready: callable = event.data callable(event.fileobj, mask) if __name__ == '__main__': server('localhost', 8888) http_client.py import socket import json import datetime def client(host, port): sock = socket.socket() sock.connect((host, port)) data = { 'send_user': 'Lyon', 'send_time': datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'), 'send_msg': 'BIO test...' } sock.send(json.dumps(data).encode('utf-8')) sock.close() print('客户端发送数据成功...') if __name__ == '__main__': client('localhost', 8888) 我们通过回调的方式 , 让IO操作都变成了异步操作 , 但是 recv 也就是数据从内核拷贝到程序中还是同步的 回调地狱 虽然通过回调函数 + IO多路复用实现了异步IO , 但是这种方式实际上存在 回调地狱(callback hell) 问题 在上面的代码中 , 我们的 accept 和 handle_conn 已经出现了两层回调 , 我们可以加入一些代码来看看 aio_callback_server.py import socket from selectors import DefaultSelector, EVENT_READ, EVENT_WRITE def server(host, port): selector = DefaultSelector() sock = socket.socket() sock.bind((host, port)) sock.listen(5) sock.setblocking(False) def accept(sock, mask): print('Accept ...') conn, addr = sock.accept() def connect(conn, mask): print('Connect ...') data = conn.recv(1024).decode('utf-8') def write(conn, mask): print('Write ...') def success(conn, mask): print('Success ...') selector.unregister(conn) conn.close() selector.modify(conn, EVENT_READ, success) selector.modify(conn, EVENT_WRITE, write) conn.send(b'ok') selector.register(conn, EVENT_READ, connect) selector.register(sock, EVENT_READ, accept) print('启动服务端...') while True: ready = selector.select() for event, mask in ready: callable = event.data callable(event.fileobj, mask) if __name__ == '__main__': server('localhost', 8888) 再调整一下客户端 aio_callback_client.py import time import json import socket import datetime def client(host, port): sock = socket.socket() sock.connect((host, port)) data = { 'send_user': 'Lyon', 'send_time': datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'), 'send_msg': 'BIO test...' } sock.send(json.dumps(data).encode('utf-8')) time.sleep(5) sock.send(json.dumps(data).encode('utf-8')) sock.close() print('客户端发送数据成功...') if __name__ == '__main__': client('localhost', 8888) 我们只不过是在一个请求中多添加了几次读写 , 代码就变得有意思了 , 我们省略一些来看看服务端是个什么样子的 aio_callback_server.py def accept(sock, mask): print('Accept ...') def connect(conn, mask): print('Connect ...') def write(conn, mask): print('Write ...') def success(conn, mask): print('Success ...') selector.modify(conn, EVENT_READ, success) selector.modify(conn, EVENT_WRITE, write) selector.register(conn, EVENT_READ, connect) selector.register(sock, EVENT_READ, accept) 这就清晰了 , 当层次一旦变多 , 那么回调地狱就会突显 , 我们的代码即将往非人类的方向发展 , 而实际情况就是我们的业务代码通常伴随着大量的网络IO与磁盘IO , 基本上无法避免多层次情况 所以回调实现的基础上 , 衍生出了基于协程的解决方案 "},"07-生成器.html":{"url":"07-生成器.html","title":"生成器","keywords":"","body":"Attack on Tornado - 生成器 🌪 前言 在上一章中 , 我们提到了可以通过协程来避开回调地狱的问题 , 我们这一章先放下对协程的疑惑 , 先来聊一聊生成器 生成器是在 Python 2.2, PEP 255 中首次引入的 , 生成器实现了迭代器协议 , 所以我们可以说生成器是迭代器的构造器 , 通过生成器我们可以在循环中计算下一个值时不会浪费内存 , 也就是可以为我们提供惰性计算 我们来自己实现一个 range 为例 : 非惰性计算 , 一次性生成 , 你需要有足够大的内存存储结果序列 def eager_range(up_to): \"\"\"Create a list of integers, from 0 to up_to, exclusive.\"\"\" sequence = [] index = 0 while index 惰性计算 , 生成器方式 def lazy_range(up_to): \"\"\"Generator to return the sequence of integers from 0 to up_to, exclusive.\"\"\" index = 0 while index 惰性计算 , 闭包方式 def cell_range(up_to): \"\"\"Closure to return the sequence of integers from 0 to up_to, exclusive.\"\"\" index = 0 def inner(): nonlocal index while index 对于闭包而言实际上是一次调用完毕的概念 , 而对于生成器而言是暂停代码执行的概念 PyGenObject 在 Python 中 , 生成器的实现就是 PyGenObject , 我们以 Python 3.6.3 为例 , 来看看它的源代码 Include/genobject.h , 13~33行 /* _PyGenObject_HEAD defines the initial segment of generator and coroutine objects. */ #define _PyGenObject_HEAD(prefix) \\ PyObject_HEAD \\ /* Note: gi_frame can be NULL if the generator is \"finished\" */ \\ /* _frame: PyFrameObject PyFrameObject 是 Python 对 x86 平台上栈帧的模拟, 同样也是 Python 字节码的执行环境, 也就是当前的上下文 */ struct _frame *prefix##_frame; \\ /* True if generator is being executed. */ \\ char prefix##_running; /* 运行状态 */ \\ /* The code object backing the generator */ \\ PyObject *prefix##_code; /* 字节码 */ \\ /* List of weak reference. */ \\ PyObject *prefix##_weakreflist; \\ /* Name of the generator. */ \\ PyObject *prefix##_name; \\ /* Qualified name of the generator. */ \\ PyObject *prefix##_qualname; typedef struct { /* The gi_ prefix is intended to remind of generator-iterator. */ _PyGenObject_HEAD(gi) } PyGenObject; _frame (PyFrameObject) 就是生成器的上下文 , Python 在执行时实际上是一条 PyFrameObject 链 , 每个 PyFrameObject 对象中都记录了上一个栈帧对象、字节码对象、字节码执行位置位置 PyGenObject 对象对 PyFrameObject 做了进一层的封装 , 这是由于生成器的特殊性 , 因为 PyFrameObject 对象实际上是一次性的 , 所以必须由其它对象也就是 PyGenObject 来保证生成器的正常运行 关于 Python 中对 x86 平台栈帧的模拟我们不过多的说明 , 可自行阅读 《Python源码剖析：深度探索动态语言核心技术》 一书 send 在 Python 2.5, PEP 342 中 , 添加了将数据发送回暂停的生成器中的功能 , 也就是 send static PyObject * gen_send_ex(PyGenObject *gen, PyObject *arg, int exc, int closing) { /* 获取当前的线程环境 */ PyThreadState *tstate = PyThreadState_GET(); /* 照当当前生成器的 PyFrameObject 对象 */ PyFrameObject *f = gen->gi_frame; PyObject *result; ...... if (f->f_lasti == -1) { /* 未激活 */ if (arg && arg != Py_None) { char *msg = \"can't send non-None value to a \" \"just-started generator\"; if (PyCoro_CheckExact(gen)) { msg = NON_INIT_CORO_MSG; } else if (PyAsyncGen_CheckExact(gen)) { msg = \"can't send non-None value to a \" \"just-started async generator\"; } PyErr_SetString(PyExc_TypeError, msg); return NULL; } } else { /* Push arg onto the frame's value stack */ result = arg ? arg : Py_None; Py_INCREF(result); /* 如果有参数, 就将其压入栈中 */ *(f->f_stacktop++) = result; } /* Generators always return to their most recent caller, not * necessarily their creator. */ Py_XINCREF(tstate->frame); assert(f->f_back == NULL); f->f_back = tstate->frame; gen->gi_running = 1; /* 将生成器设置为运行状态 */ result = PyEval_EvalFrameEx(f, exc); /* 运行生成器 */ gen->gi_running = 0; /* Don't keep the reference to f_back any longer than necessary. It * may keep a chain of frames alive or it could create a reference * cycle. */ assert(f->f_back == tstate->frame); Py_CLEAR(f->f_back); /* If the generator just returned (as opposed to yielding), signal * that the generator is exhausted. */ ...... if (!result || f->f_stacktop == NULL) { /* generator can't be rerun, so release the frame */ /* first clean reference cycle through stored exception traceback */ PyObject *t, *v, *tb; t = f->f_exc_type; v = f->f_exc_value; tb = f->f_exc_traceback; f->f_exc_type = NULL; f->f_exc_value = NULL; f->f_exc_traceback = NULL; Py_XDECREF(t); Py_XDECREF(v); Py_XDECREF(tb); gen->gi_frame->f_gen = NULL; gen->gi_frame = NULL; Py_DECREF(f); } return result; } 通过 send , 将数据回传到暂停的生成器 , 随后将生成器中的栈帧对象挂载到当前线程上 , 执行完毕后再从当前线程上卸载 , 这样就实现了生成器的调用 send 的出现使我们可以进一步对生成器进行控制 生成器的另一种调用方式 next 实际上就是 send(None) static PyObject * gen_iternext(PyGenObject *gen) { return gen_send_ex(gen, NULL, 0, 0); } yield from 在 Python 3.3, PEP 380 , 增加了 yield from , 让你可以以一种干净的方式重构生成器 , 或者说构造生成器链 def lazy_range(up_to): \"\"\"Generator to return the sequence of integers from 0 to up_to, exclusive.\"\"\" index = 0 def gratuitous_refactor(): nonlocal index while index 生成器链 def bottom(): # Returning the yield lets the value that goes up the call stack to come right back # down. return (yield 42) def middle(): return (yield from bottom()) def top(): return (yield from middle()) # Get the generator. gen = top() value = next(gen) print(value) # Prints '42'. try: value = gen.send(value * 2) except StopIteration as exc: value = exc.value print(value) # Prints '84'. 有了生成器的底子 , 我们就可以展开协程篇章了 "},"08-协程.html":{"url":"08-协程.html","title":"协程","keywords":"","body":"Attack on Tornado - 协程 🌪 前言 协程其实比线程更为古老 , 那时候只有一个CPU在执行任务 , 为了实现在一个核心上的并发 , 就有了协程 ; 而要支持并发 , 那就必须将任务拆分成多任务 , 再将这些任务按照某种顺序合并成一条新的时间执行线 , 这正是异步程序 异步是实现并发的一种方式 , 实现并发的方式也不仅仅只有异步一种 , 我们在这里只针对单线程以及协程展开 协程(Coroutine) , 就是一组可以协同工作 (协作式) 的子程序 , 协程实际上是一个很普通的函数 , 或者一个代码块 , 或者子过程 , 再或者说协程就是你可以暂停执行的函数 在 Python 中 , 可以暂停执行的函数就是生成器函数 , 也就是使用了 yield 关键字的函数 , 但这不代表生成器就是协程 , 只能说生成器可以作为协程使用 , 关于这一点你可以在《流畅的Python》第16章-协程篇找到答案 生成器只能把控制权转交给调用生成器的调用者 , 而协程讲究的是多任务协作 , 协程可以将执行权交给其他协程 ; 生成器用于生产数据 , 协程消费数据 , 且协程与迭代无关 ; 生成器实际上属于协程的子集 , 所以生成器也叫做 \"半协程\" 协程 在上一篇《生成器》中我们了解了 Python 中生成器的发展 , 实际上这不仅仅是生成器的发展 , 也是协程的进步 从最初我们使用 yield 构建可中断函数 , 再到 send 可以调度生成器函数 , 再到 yield from 可以构建生成器调用链 (这个调用链至关重要 , 因为 send 只是发送数据 , 而 yield from 可以直接调度其他生成器) 拥有了这些基础 , 协程的实现就变得简单了起来 我们先来看两段代码 : import queue def task(name, work_queue): if work_queue.empty(): print(f\"Task {name} nothing to do\") else: while not work_queue.empty(): count = work_queue.get() total = 0 print(f\"Task {name} running\") for x in range(count): total += 1 print(f\"Task {name} total: {total}\") def main(): \"\"\" This is the main entry point for the program \"\"\" # Create the queue of work work_queue = queue.Queue() # Put some work in the queue for work in [15, 10, 5, 2]: work_queue.put(work) # Create some synchronous tasks tasks = [(task, \"One\", work_queue), (task, \"Two\", work_queue)] # Run the tasks for t, n, q in tasks: t(n, q) if __name__ == \"__main__\": main() 运行结果 : Task One running Task One total: 15 Task One running Task One total: 10 Task One running Task One total: 5 Task One running Task One total: 2 Task Two nothing to do 接下来我们使用 yield 来改造一下 : import queue def task(name, queue): while not queue.empty(): count = queue.get() total = 0 print(f\"Task {name} running\") for x in range(count): total += 1 yield print(f\"Task {name} total: {total}\") def main(): \"\"\" This is the main entry point for the program \"\"\" # Create the queue of work work_queue = queue.Queue() # Put some work in the queue for work in [15, 10, 5, 2]: work_queue.put(work) # Create some tasks tasks = [task(\"One\", work_queue), task(\"Two\", work_queue)] # Run the tasks done = False while not done: for t in tasks: try: next(t) except StopIteration: tasks.remove(t) if len(tasks) == 0: done = True if __name__ == \"__main__\": main() 运行结果 : Task One running Task Two running Task Two total: 10 Task Two running Task One total: 15 Task One running Task Two total: 5 Task One total: 2 同样是两个 task , 在第二段代码中我们实现了异步执行 , 两个 task 交叉协作完成任务 , 这两个 task 就是两个协程 不难发现 , 即使我们不用 yield , 我们自己通过函数也可以实现这样的并发效果 , 把上面的代码按照 yield 拆分成几个函数功能上是一样的 , 我们把拆分的函数叫做子例程 , 实际上 , 子例程可以看做是特定状态的协程 , 任何的子例程都可以转写成不使用 yield 的协程 子例程与协程 相对于子例程而言 , 协程更加灵活 , 协程更加适合用来实现彼此比较熟悉的程序组件 , 或者说耦合度高一点的组件 协程的切换概念是 \"让步\" , 而子例程的切换概念是 \"出产\" , 一个主动 , 一个被动 , 以下摘自 Wiki : 子例程可以调用其他子例程 , 调用者等待被调用者结束后继续执行 , 故而子例程的生命期遵循后进先出 , 即最后一个被调用的子例程最先结束返回 , 协程的生命期完全由对它们的使用需要来决定 子例程的起始处是惟一的入口点 , 每当子例程被调用时，执行都从被调用子例程的起始处开始 , 协程可以有多个入口点 , 协程的起始处是第一个入口点 , 每个 yield 返回出口点都是再次被调用执行时的入口点 子例程只在结束时一次性的返回全部结果值 , 协程可以在 yield 时不调用其他协程 , 而是每次返回一部分的结果值 , 这种协程常称为生成器或迭代器 我们再回到协程 , 在本篇文章开头就已经说过 , 协程实际上早在线程之前就已经出现了 , 但是为什么协程却没有被更广泛的使用 , 而是线程占据主导地位呢 ? 线程与协程 线程与协程在某些情况下其实是没有可比性的 , 因为在现代 , 线程是 CPU 调度的基本单位 , 而协程根本不会参与 CPU 调度 从调度方式来讲 , 线程的调度是由操作系统控制的 , 且是抢占式的 ; 而协程的调度方式是由用户自己控制的 , 这种调度需要我们的程序去控制 , 且也无法像线程一样强制中断 , 需要程序自己主动让出执行权 , 所以协程通常是协作式或者说非抢占式的 从开销成本来讲 , 线程的上下文切换自然要比协程的上下文切换的开销要大 , 且线程属于系统对象 , 对系统资源消耗也比协程要大 , 这也是为什么有的人把协程叫做 \"微线程\" , 但是要注意 , 这并不意味着协程能和线程媲美 从利用核心来讲 , 线程是可以利用多核的 , 虽然在 Python 中由于 GIL 锁无法利用多核优势 , 但是实际上很多语言中线程是可以利用多核的 , 而协程只能跑在线程上 , 不管有没有 GIL 都无法利用多核 从 IO 来讲 , 当程序中遇到 IO 时 , 线程会被阻塞 , 所以协程自然也会被阻塞 , 但是在多线程的情况下每个线程之间的阻塞互不影响 , 而 CPU 时间片是由系统分配的 , 如果线程处于等待状态 , 系统自然会将时间片分配给其他线程继续执行 , 这也是我们并发模型中使用最多的多线程模型 , 此时协程针对 IO 就已经捉襟见肘了 综上 , 不管是在 CPU 密集型的业务下 , 还是在 IO 密集型的业务下 , 协程都不如线程 ; CPU 密集型场景下 , 我们要提高 CPU 的利用率 , 有几个核心那就用几个核心 , 如果一个核心配备一个线程 , 那就没有线程之间的切换了 , 开销自然不算是什么问题 ; IO 密集型场景下 , 协程整个阻塞 , 根本无法使用 这样一比较好像协程毫无用处 , 但是不要忘记了 , 遇到 IO 当前线程也没法继续执行 , 多线程只不过是切换到了其他就绪的线程罢了 , 在 Python 2 中默认线程每执行100个字节码就会切换(可通过 sys.getcheckinterval() 获取) , 而在 Python 3 中则改成了固定时间切换(可通过 sys.getswitchinterval 获取) , 而这种僵硬的调度方式会导致很多无效的切换 , 当线程数越大 , 带来的性能损耗就越大 我们之所以切换实际上更多的原因是由于有 IO 阻塞(当然也有公平性) , 所以为了降低这种性能损耗 , 我们可以改变 IO 的处理方式 , 让线程可以跳过 IO 且不丢失 CPU 的利用率 , 在前面的文章中已经介绍了6种IO模型 , 这里要说的正是IO多路复用模型 , 而这个模型带给我们的挑战就是 , 我们需要通过回调的方式来实现我们的业务 , 而回调嵌套就形成了回调链也就是回调地狱 回调与协程 我们先来回顾一下《AIO实现》中的例子 : 回调版本 import socket from selectors import DefaultSelector, EVENT_READ, EVENT_WRITE def server(host, port): selector = DefaultSelector() sock = socket.socket() sock.bind((host, port)) sock.listen(5) sock.setblocking(False) def accept(sock, mask): print('Accept ...') conn, addr = sock.accept() def connect(conn, mask): print('Connect ...') data = conn.recv(1024).decode('utf-8') def write(conn, mask): print('Write ...') def success(conn, mask): print('Success ...') selector.unregister(conn) conn.close() selector.modify(conn, EVENT_READ, success) selector.modify(conn, EVENT_WRITE, write) conn.send(b'ok') selector.register(conn, EVENT_READ, connect) selector.register(sock, EVENT_READ, accept) print('启动服务端...') while True: ready = selector.select() for event, mask in ready: callable = event.data callable(event.fileobj, mask) if __name__ == '__main__': server('localhost', 8888) 在回调版本中 , 我们抽出回调部分 : def accept(sock, mask): print('Accept ...') def connect(conn, mask): print('Connect ...') def write(conn, mask): print('Write ...') def success(conn, mask): print('Success ...') selector.modify(conn, EVENT_READ, success) selector.modify(conn, EVENT_WRITE, write) selector.register(conn, EVENT_READ, connect) selector.register(sock, EVENT_READ, accept) # 同步调用(由上而下): accept -> connect -> write -> success # 异步调用(由内而外): accept(connect(write(success()))) 回调就意味着程序有依赖关系 , 而依赖关系就会形成回调链 , 回调链一旦过长就会就成了回调地狱 , 因为我们不知道事件什么时候可以完成 , 所以我们必须预先定义好事件完成后将要回调的函数 , 如果我们能够在事件开始监听时中断程序 , 在事件完成回调时恢复程序 , 是不是就不需要预先定义回调函数了呢 ? 不管回调链有多长 , 我们只需要让程序不断的自我中断 , 再恢复 , 直到程序执行完毕 , 一切似乎就变得简单起来了 , 那我们要怎么去实现呢 ? 答案是 : 协程 那么让我们来改造一下上面这段代码 : import socket from inspect import isfunction from selectors import DefaultSelector, EVENT_READ, EVENT_WRITE def server(host, port): selector = DefaultSelector() sock = socket.socket() sock.bind((host, port)) sock.listen(5) sock.setblocking(False) def handler(): gen = accept() gen.send(None) gen.send(gen) def accept(): gen = yield print('Accept ...') conn, addr = sock.accept() selector.register(conn, EVENT_READ, gen) yield print('Connect ...') data = conn.recv(1024).decode('utf-8') selector.modify(conn, EVENT_WRITE, gen) conn.send(b'ok') yield print('Write ...') selector.modify(conn, EVENT_READ, gen) yield print('Success ...') selector.unregister(conn) conn.close() yield selector.register(sock, EVENT_READ, handler) print('启动服务端...') while True: ready = selector.select() for event, mask in ready: if isfunction(event.data): event.data() else: try: event.data.send(event.fileobj) except StopIteration as e: continue if __name__ == '__main__': server('localhost', 8888) 每一次 yield 都将执行权限让出 , 等待事件回调发生 , 这就是协程的魅力 , 回调的异步代码变成了一种同步的方式 不过 , 如果我们这样去编写异步程序 , 那也得费不少劲 , 虽然代码看着同步了 , 但是回调注册却并友好 , 有没有法子可以让我们不关心回调注册 ? 先思考一下 , 在下一篇《AIO协程实现》中 , 我们再来优化 协程给我们带来的最大好处实际上并不是性能 , 而是我们可以通过协程来将异步代码用同步的方式编写 现在我们其实还有一个问题那就是协程如何调度 , 这就是我们接下来要说的事件循环 事件循环 事件循环 是一种程序结构或设计模式 , 用于在程序中等待和分发事件或者消息 , 简单来说就是当某件事情发生时 , 接下来该做什么 , 通常它是一个死循环 , 因为它需要不断的收集事件并处理事件 在上面的代码中其实我们已经实现了一个最简单的事件循环 : # 永不停歇的收集事件并处理事件 while True: # 收集就绪的事件列表 ready = selector.select() # 循环处理事件 for event, mask in ready: if isfunction(event.data): event.data() else: try: event.data.send(event.fileobj) except StopIteration as e: continue 事件循环上就是一个调度器 , 是我们用户程序之间的调度器 , 就是操作系统调度线程一样 , 事件循环可以用来调度我们的协程 , 所以通常你会发现协程总是和事件循环同时出现 , 所以我们对事件循环的要求一般都比较高 , 因为协程调度的性能直接由事件循环的调度方案决定 在早期的 Python 中 , 由 gevent 提供了事件循环能力 , 而 Python 3.4 时引入 asyncio 标准库来提供事件循环能力 关于事件循环的具体实现 , 请阅读后续文章 async&await 最后我们来说说 async 和 await 在 Python 3.4 中 # This also works in Python 3.5. import asyncio.coroutine @asyncio.coroutine def py34_coro(): yield from stuff() 对应的字节码 >>> dis.dis(py34_coro) 2 0 LOAD_GLOBAL 0 (stuff) 3 CALL_FUNCTION 0 (0 positional, 0 keyword pair) 6 GET_YIELD_FROM_ITER 7 LOAD_CONST 0 (None) 10 YIELD_FROM 11 POP_TOP 12 LOAD_CONST 0 (None) 15 RETURN_VALUE 在 Python 3.5 中 async def py35_coro(): await stuff() 对应的字节码 >>> dis.dis(py35_coro) 1 0 LOAD_GLOBAL 0 (stuff) 3 CALL_FUNCTION 0 (0 positional, 0 keyword pair) 6 GET_AWAITABLE 7 LOAD_CONST 0 (None) 10 YIELD_FROM 11 POP_TOP 12 LOAD_CONST 0 (None) 15 RETURN_VALUE 它们之间的差异仅仅是 GET_YIELD_FROM_ITER 和 GET_AWAITABLE 的差异 , 而这两个函数实际上都是用来标记协程的 , 所以其实 yield from 和 async/await 并无两样 GET_YIELD_FROM_ITER 可以接收生成器或者协程 , 而 GET_AWAITABLE 只接受协程 所以 async/await 并没有做什么特殊的提升 , 这两个关键字也主要是为了将协程规范化 , 明确了协程的意义 , 而不是将生成器和协程混在一起 这些也都是有迹可循的 : 3.4：asyncio 在 Python 标准库中引入 , 但是只是临时的 3.5：async/await 成为 Python 语法的一部分 , 用于表示和等待协程 , 但它们还不是保留关键字 3.6：引入了异步生成器和异步循环 , asyncio 不再只是临时的 , 而是稳定的 3.7：async/await 成为保留关键字 , 它们旨在替换 asyncio.coroutine() 装饰器 到这里 , 协程的前世今生我们已经理清了 , 不过还有一点 , gevent 是有栈协程的代表 , 而 asyncio 是无栈协程的代表 , 关于有栈协程和无栈协程的具体细节 , 请关注我后续的文章 最后我们来简单总结一下 总结 协程难的原因其实不是它本身 , 而是我们需要从历史出发 , 理清它的前世今生 网络上关于协程相关的文章更多的是用法 , 而从用法出发 , 很多东西都已经被隐藏了 , 导致中间出现了断层 在本篇中 , 我们并没有介绍协程的用法 , 而是从源头出发 : 协程实际上是为了解决单核多任务并发问题 协程可以降低异步回调的复杂性 , 将异步代码同步化(这里只是说编写风格) 协程需要有事件循环来调度 async/awiat 可以看做是 yield from 的语法糖 , 将生成器与协程进行隔离 参考资料 《流畅的Python》 python-async-features how-the-heck-docs-async-await-work-in-python-3.5 i-dont-understand-asyncio 深入理解 Python 异步编程（上） "},"09-AIO协程实现.html":{"url":"09-AIO协程实现.html","title":"AIO协程实现","keywords":"","body":"Attack on Tornado - AIO协程实现 🌪 前言 虽然在上一篇中我们通过协程解决了回调地狱问题 , 但是回调注册方式还是不够简单 , 因为作为用户来讲 , 我们不应该去关心注册回调事件 我们希望有一个回调控制器可以自动帮我们注册回调 , 我们只关心业务逻辑 , 而对我们而言业务逻辑必然处于协程中 , 那么这个控制器肯定是从事件循环入手了 AIO协程进阶 我们可以定义一个基类 Event , 其中定义两个 API 分别控制 : 注册回调事件与处理回调事件 , 随后每种事件都继承基类 Event , 在使用时 , 直接将事件推入事件循环 , 统一由事件循环进行调度 class Event: def _yield(self, loop, task): \"\"\"用于注册回调\"\"\" raise NotImplementedError def _resume(self, loop, task): \"\"\"处理回调, 并将回调函数放入准备队列\"\"\" raise NotImplementedError 我们定义两种事件 , Accept 和 Read 事件 , 用于接收请求并接收请求中的数据 class ReadEvent(Event): def __init__(self, sock): self.sock = sock def _yield(self, loop, task): loop._read_wait(self.sock.fileno(), self, task) def _resume(self, loop, task): data = self.sock.recv(1024) loop._ready.append((task, data)) class AcceptEvent(Event): def __init__(self, sock): self.sock = sock def _yield(self, loop, task): loop._read_wait(self.sock.fileno(), self, task) def _resume(self, loop, task): r = self.sock.accept() loop._ready.append((task, r)) 事件循环除了维护事件队列之外 , 还维护一个就绪任务队列用于执行跟事件无关的其他业务逻辑 import select from collections import deque class EventLoop: def __init__(self): self._num_tasks = 0 # Total num of tasks self._ready = deque() # Tasks ready to run self._read_waiting = {} # Tasks waiting to read self._write_waiting = {} # Tasks waiting to write def _io_poll(self): \"\"\" Poll for I/O events and restart waiting tasks \"\"\" if -1 in self._read_waiting: self._read_waiting.pop(-1) # 这里只是为了方便调试所以使用的select r_set, w_set, e_set = select.select(self._read_waiting, self._write_waiting, []) for r in r_set: event, task = self._read_waiting.pop(r) event._resume(self, task) def call_soon(self, task): self._ready.append((task, None)) self._num_tasks += 1 def _read_wait(self, fileno, event, task): \"\"\" Add a event to the reading set \"\"\" self._read_waiting[fileno] = (event, task) def run_forever(self): ''' Run the task eventloop until there are no tasks ''' while self._num_tasks: if not self._ready: self._io_poll() task, data = self._ready.popleft() try: # Run the coroutine to the next yield r = task.send(data) if isinstance(r, Event): r._yield(self, task) else: raise RuntimeError('unrecognized yield event') except StopIteration: self._num_tasks -= 1 因为我们需要循环不断的接收请求 , 所以我们还需要编写一个接收函数以及处理函数 if __name__ == '__main__': import socket def handle_events(conn): while True: line = yield ReadEvent(conn) print(line.decode('utf-8')) conn.close() def server_loop(loop, host, port): sock = socket.socket() sock.bind((host, port)) sock.listen(5) sock.setblocking(False) print('启动服务端...') while True: conn, a = yield AcceptEvent(sock) print('Got connection from ', a) loop.call_soon(handle_events(conn)) loop = EventLoop() loop.call_soon(server_loop(loop, 'localhost', 8888)) loop.run_forever() 当然还有 client import time import json import socket import datetime def client(host, port): sock = socket.socket() sock.connect((host, port)) data = { 'send_user': 'Lyon', 'send_time': datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'), 'send_msg': 'BIO test...' } sock.send(json.dumps(data).encode('utf-8')) time.sleep(5) sock.send(json.dumps(data).encode('utf-8')) sock.close() print('客户端发送数据成功...') if __name__ == '__main__': client('localhost', 8888) 就这样我们的优化就完成了 , 我们可以把其他跟事件无关的任务通过 call_soon 方法添加到 _ready 就绪队列中 , 就像 server_loop 现在已经很接近 asyncio 了 , 只不过我们要达到像 asyncio 支持的那样 , 还需要做不少工作 , 我们的目的是去理解这种编程方式 , 所以下一篇我们直接介绍 asyncio 参考资料 《Python Cookbook》 "},"09-asyncio.html":{"url":"09-asyncio.html","title":"asyncio","keywords":"","body":"Attack on Tornado - asyncio 🌪 "},"10-IOLoop.html":{"url":"10-IOLoop.html","title":"IOLoop","keywords":"","body":"Attack on Tornado - IOLoop 🌪 介绍 IOLoop 是异步非阻塞模型的关键所在 , 我们以 asyncio 为例来分析 Tornado 的源码实现 开始 我们会围绕官方的一个例子来进行源码分析 , 示例如下 : import tornado.ioloop import tornado.web class MainHandler(tornado.web.RequestHandler): def get(self): self.write(\"Hello, world\") if __name__ == \"__main__\": application = tornado.web.Application([ (r\"/\", MainHandler), ]) application.listen(8888) tornado.ioloop.IOLoop.current().start() 为了节省篇幅 , 会省略部分官方注释 , 因为本节的重点不在 tornado.web.Application 这个应用对象上 , 所以我们在这节中不会过多的去分析 Application Configurable 在开始之前 , 我们需要先看一下 Configurable 的源码 , 因为它改变了我们正常对象初始化流程 , 且在 Tornado 中基本大多数类都继承了 Configurable # type: tornado.util.Configurable class Configurable(object): __impl_class = None # type: Optional[Type[Configurable]] __impl_kwargs = None # type: Dict[str, Any] def __new__(cls, *args: Any, **kwargs: Any) -> Any: base = cls.configurable_base() init_kwargs = {} # type: Dict[str, Any] if cls is base: impl = cls.configured_class() if base.__impl_kwargs: init_kwargs.update(base.__impl_kwargs) else: impl = cls init_kwargs.update(kwargs) if impl.configurable_base() is not base: # The impl class is itself configurable, so recurse. return impl(*args, **init_kwargs) # 调用object的__new__方法 instance = super(Configurable, cls).__new__(impl) # 调用实例的 initialize 方法 # 在Tornado中, 继承了 Configurable 的类的 __init__ 基本都是 pass 带过 # 真正的初始化都放在 initialize 方法中, 所以如果你发现了 initialize , 那么没错, 它就是真正的 `__init__` instance.initialize(*args, **init_kwargs) return instance listen application.listen def listen(self, port: int, address: str = \"\", **kwargs: Any) -> HTTPServer: # type: tornado.httpserver.HTTPServer(TCPServer, Configurable, httputil.HTTPServerConnectionDelegate) # type: tornado.tcpserver.TCPServer server = HTTPServer(self, **kwargs) # type: tornado.tcpserver.TCPServer.listen server.listen(port, address) return server tornado.tcpserver.TCPServer.listen def listen(self, port: int, address: str = \"\") -> None: # type: tornado.netutil.bind_sockets # bind_sockets是用来创建套接字的, 默认会根据系统需要创建相应的套接字 # 以Mac为例, 会创建出 AF_INET 和 AF_INET6 两个套接字 \"\"\" sockets : [ , ] \"\"\" sockets = bind_sockets(port, address=address) # type: tornado.tcpserver.TCPServer.add_sockets self.add_sockets(sockets) tornado.tcpserver.TCPServer.add_sockets def add_sockets(self, sockets: Iterable[socket.socket]) -> None: for sock in sockets: # self._sockets, self._handlers 是两个dict # sock.fileno()会返回一个文件描述符, 然后以文件描述符为key, socket对象为value存储到server对象中 # sock type: socket.socket() self._sockets[sock.fileno()] = sock # type: tornado.netutil.add_accept_handler # 在add_accept_handler中会完成IOLoop的创建, 以及套接字绑定到事件循环上 self._handlers[sock.fileno()] = add_accept_handler( sock, self._handle_connection ) # slef._handle_connection 看名字我们也能知道这是处理连接的回调函数 add_accept_handler tornado.netutil.add_accept_handler def add_accept_handler( sock: socket.socket, callback: Callable[[socket.socket, Any], None] ) -> Callable[[], None]: # type: tornado.platform.asyncio.AsyncIOMainLoop(BaseAsyncIOLoop) # type: tornado.platform.asyncio.BaseAsyncIOLoop(IOLoop) # type: tornado.ioloop.IOLoop # IOLoop.current(instance=True) => tornado.ioloop.IOLoop.current \"\"\" 在这里有一个关键的地方就是在 AsyncIOMainLoop(make_current=True)的时候 def initialize(self, **kwargs: Any) -> None: # type: ignore 这里会使用asyncio去获取到当前的事件循环, 并作为参数, 到达BaseAsyncIOLoop.initialize super().initialize(asyncio.get_event_loop(), **kwargs) \"\"\" io_loop = IOLoop.current() # 其他部分暂时省略, 我们先看看IOLoop是怎么创建的 tornado.platform.asyncio.AsyncIOMainLoop.initialize def initialize(self, **kwargs: Any) -> None: # type: ignore # 这里很关键, 因为它其实使用了asyncio去获取当前线程的事件循环, 然后将拿到的eventloop作为参数传入了BaseAsyncIOLoop.initialize super().initialize(asyncio.get_event_loop(), **kwargs) tornado.platform.asyncio.BaseAsyncIOLoop.initialize def initialize(self, asyncio_loop: asyncio.AbstractEventLoop, **kwargs: Any) -> None: # 这里可以看到官方的标注是asyncio.AbstractEventLoop, 实际上asyncio这里的实现要复杂得多, 我们可以放在后面的文章中 # 如果你看过asyncio的源码, 那在这里千万别搞混了, 因为tornado.ioloop.IOLoop实际上是讲asyncio中的loop作为一个或者说两个属性来使用的, 并不是继承的方式, 所以两者存在一些差异 self.asyncio_loop = asyncio_loop self.selector_loop = asyncio_loop if hasattr(asyncio, \"ProactorEventLoop\") and isinstance( asyncio_loop, asyncio.ProactorEventLoop # type: ignore ): self.selector_loop = AddThreadSelectorEventLoop(asyncio_loop) self.handlers = {} self.readers = set() # type: Set[int] self.writers = set() # type: Set[int] self.closing = False for loop in list(IOLoop._ioloop_for_asyncio): if loop.is_closed(): del IOLoop._ioloop_for_asyncio[loop] # 在这里就会讲asyncio_loop存放到IOLoop的类变量中 # 这里要注意的, 在其他的地方可能会使用asyncio的get_event_loop方法来获取asyncio_loop # 这样再通过asyncio_loop就可以到类变量中拿到tornado.platform.asyncio.AsyncIOMainLoop # 你可以在IOLoop的current中看到这块代码 IOLoop._ioloop_for_asyncio[asyncio_loop] = self self._thread_identity = 0 super().initialize(**kwargs) # assign_thread_identity将会在IOLoop.start()的时候被回调 def assign_thread_identity() -> None: self._thread_identity = threading.get_ident() # type: tornado.platform.asyncio.BaseAsyncIOLoop.add_callback # 这个add_callback其实使用的就是asyncio中loop的add_callback, 它的做用哪个就是添加一个回调函数到事件循环中 self.add_callback(assign_thread_identity) 这种我们就大费周章的拿到了 io_loop , 所以我们再回到 tornado.netutil.add_accept_handler def add_accept_handler( sock: socket.socket, callback: Callable[[socket.socket, Any], None] ) -> Callable[[], None]: # type: tornado.platform.asyncio.AsyncIOMainLoop(BaseAsyncIOLoop) # type: tornado.platform.asyncio.BaseAsyncIOLoop(IOLoop) # type: tornado.ioloop.IOLoop # IOLoop.current(instance=True) => tornado.ioloop.IOLoop.current io_loop = IOLoop.current() removed = [False] # 这里我们先省略accept_handler, 等到真正使用的时候再分析 def accept_handler(fd: socket.socket, events: int) -> None: pass def remove_handler() -> None: io_loop.remove_handler(sock) removed[0] = True # type: tornado.platform.asyncio.BaseAsyncIOLoop.add_handler # 在这里注册了一个读事件 io_loop.add_handler(sock, accept_handler, IOLoop.READ) return remove_handler add_handler tornado.platform.asyncio.BaseAasyncIOLoop.add_handler def add_handler( self, fd: Union[int, _Selectable], handler: Callable[..., None], events: int ) -> None: fd, fileobj = self.split_fd(fd) if fd in self.handlers: raise ValueError(\"fd %s added twice\" % fd) # 这里self.handlers中存储的是以文件描述符为key, 套接字对象和 accept_handler 组成的元祖为value的dict self.handlers[fd] = (fileobj, handler) if events & IOLoop.READ: # type: asyncio.selector_evnets.add_reader # 添加一个读事件的回调 self.selector_loop.add_reader(fd, self._handle_events, fd, IOLoop.READ) self.readers.add(fd) if events & IOLoop.WRITE: self.selector_loop.add_writer(fd, self._handle_events, fd, IOLoop.WRITE) self.writers.add(fd) asyncio.selector_events.add_reader def add_reader(self, fd, callback, *args): self._ensure_fd_no_transport(fd) # callback: tornado.platform.asyncio.BaseAsyncIOLoop._handle_events # type: asyncio.selector_events.BaseSelectorEventLoop._add_reader return self._add_reader(fd, callback, *args) asyncio.selector_events.BaseSelectorEventLoop._add_reader def _add_reader(self, fd, callback, *args): self._check_closed() handle = events.Handle(callback, args, self) try: key = self._selector.get_key(fd) except KeyError: # self._selector是一个多路复用器, 因为我们主要是在Linux上运行 # 所以 type: selectors.EpollSelector # 在Mac上使用的是 selectors.KqueueSelector # 这里会将一个读事件注册到IO多路复用器中 self._selector.register(fd, selectors.EVENT_READ, (handle, None)) else: mask, (reader, writer) = key.events, key.data self._selector.modify(fd, mask | selectors.EVENT_READ, (handle, writer)) if reader is not None: reader.cancel() 实际上 , 到这里 , 我们的初始化流程就已经完成了 然后我们调用 tornado.ioloop.IOLoop.current().start() 如果光看示例 , 你可以会疑惑 , 我什么现在又调用 IOLoop.current() , 且没有明显的将事件循环和 Tornado 的应用绑定起来 , 所以到这里你应该就没有疑惑了 , 因为在 listen 中 , 做了太多的事情了 tornado.ioloop.current().start() # type: tornado.platform.asyncio.BaseAsyncIOLoop.start def start(self) -> None: try: old_loop = asyncio.get_event_loop() except (RuntimeError, AssertionError): old_loop = None # type: ignore try: self._setup_logging() # type: asyncio.base_events.BaseEventLoop.run_forever asyncio.set_event_loop(self.asyncio_loop) self.asyncio_loop.run_forever() finally: asyncio.set_event_loop(old_loop) asyncio.base_events.BaseEventLoop.run_forever def run_forever(self): \"\"\"Run until stop() is called.\"\"\" self._check_closed() if self.is_running(): raise RuntimeError('This event loop is already running') if events._get_running_loop() is not None: raise RuntimeError( 'Cannot run the event loop while another loop is running') self._set_coroutine_wrapper(self._debug) self._thread_id = threading.get_ident() if self._asyncgens is not None: old_agen_hooks = sys.get_asyncgen_hooks() sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook, finalizer=self._asyncgen_finalizer_hook) try: events._set_running_loop(self) while True: # 从这里整个线程就进入了死循环当中 # type: asyncio.base_events.BaseEventLoop._run_once # 每当有新的事件产生时, _run_once就会被循环一次 self._run_once() if self._stopping: break finally: self._stopping = False self._thread_id = None events._set_running_loop(None) self._set_coroutine_wrapper(False) if self._asyncgens is not None: sys.set_asyncgen_hooks(*old_agen_hooks) _handle_events 在我们分析 _run_once 之前 , 我们需要先看一下 _handle_events , 因为它这才是事件发生时的回调函数 tornado.platform.asyncio.BaseAsyncIOLoop._handle_events def _handle_events(self, fd: int, events: int) -> None: # 其实这里的操作很简单, 就是根据监听的文件描述符, 到handlers中获取socket和handler_func # 这里的handler_func就是accept_handler, 也就是我们在调用add_accept_handler的时候里面调用的io_loop.add_handler(sock, accept_handler, IOLoop.READ) 这里放进去的 # 所以我们到这里可以去看accept_handler了 fileobj, handler_func = self.handlers[fd] handler_func(fileobj, events) accept_handler # type: tornado.tcpserver.TCPServer._handle_connection callback = self._handle_connection def accept_handler(fd: socket.socket, events: int) -> None: for i in range(_DEFAULT_BACKLOG): if removed[0]: # The socket was probably closed return try: # 其实就是当有连接过来时, 就拿到conn和address, 然后进行回调 # 回调就是在add_sockets的时候设置的 self._handle_connection connection, address = sock.accept() except BlockingIOError: # EWOULDBLOCK indicates we have accepted every # connection that is available. return except ConnectionAbortedError: # ECONNABORTED indicates that there was a connection # but it was closed while still in the accept queue. # (observed on FreeBSD). continue callback(connection, address) _handle_connection tornado.tcpserver.TCPServer._handle_connection def _handle_connection(self, connection: socket.socket, address: Any) -> None: # 我们把ssl部分直接略过 if self.ssl_options is not None: pass try: if self.ssl_options is not None: stream = SSLIOStream( connection, max_buffer_size=self.max_buffer_size, read_chunk_size=self.read_chunk_size, ) # type: IOStream else: # type: tornado.iostream.IOStream stream = IOStream( connection, max_buffer_size=self.max_buffer_size, read_chunk_size=self.read_chunk_size, ) # type: tornado.httpserver.HTTPServer.handle_stream future = self.handle_stream(stream, address) if future is not None: IOLoop.current().add_future( gen.convert_yielded(future), lambda f: f.result() ) except Exception: app_log.error(\"Error in connection callback\", exc_info=True) tornado.httpserver.HTTPServer.handle_stream def handle_stream(self, stream: iostream.IOStream, address: Tuple) -> None: context = _HTTPRequestContext( stream, address, self.protocol, self.trusted_downstream ) # 创建连接对象 conn = HTTP1ServerConnection(stream, self.conn_params, context) self._connections.add(conn) # type: tornado.http1connection.HTTP1ServerConnection.start_serving # self: tornado.httpserver.HTTPSever 继承了 tornado.httputil.HTTPServerConnectionDelegate conn.start_serving(self) tornado.http1connection.HTTP1ServerConnection.start_serving def start_serving(self, delegate: httputil.HTTPServerConnectionDelegate) -> None: assert isinstance(delegate, httputil.HTTPServerConnectionDelegate) # 构造future # delegate HTTPServer # type: tornado.http1connection.HTTP1ServerConnection._server_request_loop # 将 coroutine 包装成 Task # 实际上到这里一个请求的流程就已经完成了, 在self._server_request_loop中主要是处理请求的细节, 我们放到后面的章节中再分析 # 要注意的是, 这些Future都还没有真正执行 fut = gen.convert_yielded(self._server_request_loop(delegate)) self._serving_future = fut # self.stream.io_loop type: tornado.ioloop.IOLoop.add_future # 在add_future会调用Future.add_done_callback type: asyncio.futures.Future # add_done_callback方法会根据当前Future的状态来判断是否执行, 而最终执行还是使用的asyncio.base_events.BaseEventLoop.call_soon # 最后呢, call_soon再调用_call_soon, 将回调包装成events.Handle, 最后append到_ready队列中 self.stream.io_loop.add_future(fut, lambda f: f.result()) tornado.http1connection.HTTP1ServerConnection._server_request async def _server_request_loop( self, delegate: httputil.HTTPServerConnectionDelegate ) -> None: try: while True: conn = HTTP1Connection(self.stream, False, self.params, self.context) # delegate.start_request type: tornado.httpserver.HTTPServer.start_request request_delegate = delegate.start_request(self, conn) try: ret = await conn.read_response(request_delegate) except ( iostream.StreamClosedError, iostream.UnsatisfiableReadError, asyncio.CancelledError, ): return except _QuietException: # This exception was already logged. conn.close() return except Exception: gen_log.error(\"Uncaught exception\", exc_info=True) conn.close() return if not ret: return # 只要没有完成, 那么每次都会切换 await asyncio.sleep(0) finally: delegate.on_close(self) 所以到这里 , 基本上我们就可以知道 , 所有的请求最终都会达到 _ready 中 , 现在我们就可以看看最核心的 _run_once 到底做了什么了 _run_once asyncio.base_events.BaseEventLoop._run_once def _run_once(self): sched_count = len(self._scheduled) # self._scheduled 是关于定时任务的一些实现 # 定时任务基本上是通过 asyncio.base_events.BaseEventLoop.call_at 去做的 # 而在call_at中, 会有一个timer定时器来控制 if (sched_count > _MIN_SCHEDULED_TIMER_HANDLES and self._timer_cancelled_count / sched_count > _MIN_CANCELLED_TIMER_HANDLES_FRACTION): # Remove delayed calls that were cancelled if their number # is too high new_scheduled = [] for handle in self._scheduled: if handle._cancelled: handle._scheduled = False else: new_scheduled.append(handle) heapq.heapify(new_scheduled) self._scheduled = new_scheduled self._timer_cancelled_count = 0 else: # Remove delayed calls that were cancelled from head of queue. while self._scheduled and self._scheduled[0]._cancelled: self._timer_cancelled_count -= 1 handle = heapq.heappop(self._scheduled) handle._scheduled = False timeout = None # 刚启动进来self._ready其实是有东西的, 就是在listen的时候注册的 assign_thread_identity 函数 # 当准备好的任务中有任务时, 就直接执行 if self._ready or self._stopping: timeout = 0 # 如果现在都没有, elif self._scheduled: # Compute the desired timeout. when = self._scheduled[0]._when timeout = min(max(0, when - self.time()), MAXIMUM_SELECT_TIMEOUT) if self._debug and timeout != 0: t0 = self.time() event_list = self._selector.select(timeout) dt = self.time() - t0 if dt >= 1.0: level = logging.INFO else: level = logging.DEBUG nevent = len(event_list) if timeout is None: logger.log(level, 'poll took %.3f ms: %s events', dt * 1e3, nevent) elif nevent: logger.log(level, 'poll %.3f ms took %.3f ms: %s events', timeout * 1e3, dt * 1e3, nevent) elif dt >= 1.0: logger.log(level, 'poll %.3f ms took %.3f ms: timeout', timeout * 1e3, dt * 1e3) else: event_list = self._selector.select(timeout) # 这个时候event_list只有[(SelectorKey(fileobj=8, fd=8, events=1, data=(, None)), 1)] # 它是在BaseSelectorEventLoop初始化的时候调用的 _make_self_pipe方法放进去的 # 而_read_from_self会一直等待套接字传输数据, 并读取数据 # 你可能会想, 我们在listen的时候也注册了两个套接字, 为什么这个event_list没有它们 # 这是因为现在还没有连接进来, 所以两个事件都还没有准备好 # type: asyncio.selector_events.BaseSelectorEventLoop._process_events self._process_events(event_list) # 我们先省略下面的部分, 看看_process_events做了什么事情 asyncio.selector_events.BaseSelectorEventLoop._process_events def _process_events(self, event_list): for key, mask in event_list: fileobj, (reader, writer) = key.fileobj, key.data # 这里的 key.data 就是我们在上面_add_reader方法中所注册的 # 读事件 self._selector.register(fd, selectors.EVENT_READ, (handle, None)) # 写事件 self._selector.modify(fd, mask | selectors.EVENT_READ, (handle, writer)) # 其中 handle 是 events.Handle type: asyncio.events.Handle if mask & selectors.EVENT_READ and reader is not None: if reader._cancelled: self._remove_reader(fileobj) else: # 这个时候并不会真正的执行而是将这个回调函数, 放入 _reday 中 # type: asyncio.base_events.BaseEventLoop._add_callback self._add_callback(reader) if mask & selectors.EVENT_WRITE and writer is not None: if writer._cancelled: self._remove_writer(fileobj) else: self._add_callback(writer) asyncio.base_events.BaseEventLoop._add_callback def _add_callback(self, handle): \"\"\"Add a Handle to _scheduled (TimerHandle) or _ready.\"\"\" assert isinstance(handle, events.Handle), 'A Handle is required here' if handle._cancelled: return assert not isinstance(handle, events.TimerHandle) # 也就是我所说的, 会加入到 _reday 队列中 # type: asyncio.base_events.BaseEventLoop._ready # _ready : type: collections.queue self._ready.append(handle) 接下来我们再往 _process_events 下面看 end_time = self.time() + self._clock_resolution # 当有定时任务, 且定时任务到了执行时间时, 就会将它放入到self._ready中去执行 # 实际上这里处理的任务, 基本都是TimerHandler while self._scheduled: handle = self._scheduled[0] if handle._when >= end_time: break handle = heapq.heappop(self._scheduled) handle._scheduled = False self._ready.append(handle) ntodo = len(self._ready) for i in range(ntodo): handle = self._ready.popleft() if handle._cancelled: continue # 无论我们是不是出于DEBUG模式, 都将执行handle._run() # handler type: asyncio.events.Handler._run() if self._debug: try: self._current_handle = handle t0 = self.time() handle._run() dt = self.time() - t0 if dt >= self.slow_callback_duration: logger.warning('Executing %s took %.3f seconds', _format_handle(handle), dt) finally: self._current_handle = None else: handle._run() handle = None # Needed to break cycles when an exception occurs. asyncio.events.Handle._run def _run(self): try: # 那么这里_callback就不用在说了, 就是去执行我们_ready队列中的所有任务了 self._callback(*self._args) except Exception as exc: cb = _format_callback_source(self._callback, self._args) msg = 'Exception in callback {}'.format(cb) context = { 'message': msg, 'exception': exc, 'handle': self, } if self._source_traceback: context['source_traceback'] = self._source_traceback # 如果捕捉到异常了, 同样的, 还是加入到事件循环中去执行 # type: asyncio.base_events.BaseEventLoop.call_exception_handler self._loop.call_exception_handler(context) self = None # Needed to break cycles when an exception occurs. 因为本文的核心重点并不在 asyncio 上 , 所以关于 asyncio 并没有过多解释 通过这一节源码分析 , 我们就可以知道 , 在 Tornado 或者说 asyncio 中 , 异步非阻塞模型的实现 , 实际上只是应用层的异步非阻塞 , 在系统层还是使用的IO多路复用也就是同步IO去实现的 且 callback 如果计算过久 , 同样也会造成整个线程阻塞 , 所以如果计算过长的函数 , 可以分成多个函数 , 或者利用线程池来处理 "}}